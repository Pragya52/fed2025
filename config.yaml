# Federated Split Learning Configuration

# Model Configuration
model:
  name: "microsoft/DialoGPT-medium"  # Using a smaller model for medical QA
  embed_dim: 1024
  num_layers: 24
  vocab_size: 50257
  max_seq_length: 512
  split_layer: 6  # Split after layer 6
  
  # Client model architecture
  client:
    head_dim: 1024
    local_body_layers: 3
    tail_layers: 2
    dropout: 0.1
    
  # Server model architecture  
  server:
    body_start_layer: 6
    body_end_layer: 22
    tail_layers: 2

# Training Configuration
training:
  num_rounds: 100
  local_epochs: 5
  batch_size: 8
  learning_rate: 5e-5
  weight_decay: 0.01
  gradient_clip_norm: 1.0
  warmup_steps: 100
  
  # Federated averaging
  fedavg_frequency: 5  # fedround parameter
  
  # Knowledge distillation
  temperature: 3.0
  alpha: 0.7  # Weight for distillation loss
  beta: 0.3   # Weight for task loss

# Loss weights (from methodology)
loss_weights:
  server:
    lambda1: 0.5  # Distillation weight
    lambda2: 0.5  # Task loss weight
  client:
    mu1: 0.5      # Distillation weight  
    mu2: 0.5      # Task loss weight

# Privacy Configuration
privacy:
  gaussian_noise:
    sigma: 0.1
    enable: true
  quantization:
    bits: 8
    enable: true
  differential_privacy:
    epsilon: 1.0
    delta: 1e-5
    
# Federated Setup
federated:
  num_clients: 3
  client_selection: "all"  # or "random"
  min_available_clients: 2
  
# Data Configuration  
data:
  dataset_name: "microsoft/ms_marco"  # Medical QA dataset
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  max_samples_per_client: 10000
  iid: false  # Non-IID data distribution
  alpha: 0.5  # Dirichlet concentration parameter

# Optimization
optimizer:
  name: "AdamW"
  server_lr: 1e-4
  client_lr: 5e-5
  momentum: 0.9
  eps: 1e-8

# Evaluation
evaluation:
  eval_frequency: 10  # Every N rounds
  metrics: ["accuracy", "f1", "bleu", "rouge", "perplexity"]
  save_best_model: true

# Logging
logging:
  log_level: "INFO"
  log_file: "results/logs/training.log"
  wandb_project: "federated-medical-qa"
  save_frequency: 20

# Hardware
device: "cuda"
mixed_precision: true
dataloader_workers: 4
